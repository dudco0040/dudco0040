{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorflow문법 p26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_6:0\", shape=(), dtype=float32)\n",
      "Tensor(\"Const_7:0\", shape=(), dtype=float32)\n",
      "Tensor(\"Add_3:0\", shape=(), dtype=float32)\n",
      "sess.run(node1,node2):  [3.0, 4.0]\n",
      "sess.run(node3):  7.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "node1 = tf.constant(3.0, tf.float32)  # 실수형\n",
    "node2 = tf.constant(4.0) # data type을 지정하지 않으면 데이터에서 유추\n",
    "node3 = tf.add(node1, node2)\n",
    "#tf.constant(value, dtype = None, shape = None, name ='Const')\n",
    "\n",
    "print(node1)\n",
    "print(node2)\n",
    "print(node3)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(\"sess.run(node1,node2): \", sess.run([node1,node2]))\n",
    "    print(\"sess.run(node3): \", sess.run(node3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5\n",
      "[3. 7.]\n"
     ]
    }
   ],
   "source": [
    "a = tf.placeholder(tf.float32)  #값의 데이터 타입을 지정\n",
    "b = tf.placeholder(tf.float32)\n",
    "adder_node = a+b   # tf.add(a,b)\n",
    "\n",
    "sess = tf.Session()\n",
    "print(sess.run(adder_node, feed_dict = {a:3, b:4.5}))   #딕셔너리 형식으로 값을 받음\n",
    "print(sess.run(adder_node, feed_dict = {a:[1,3], b:[2,4]}))  #리스트 형태로 각 숫자를 더해준다.\n",
    "# feed_dict -> 값을 입력받는다.\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, Tensorflow!'\n"
     ]
    }
   ],
   "source": [
    "hello = tf.constant(\"Hello, Tensorflow!\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신경망 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.37882397 [0.7351489] [1.1059486]\n",
      "20 0.056862358 [0.7230455] [0.6295826]\n",
      "40 0.021484137 [0.82976264] [0.38698953]\n",
      "60 0.008117273 [0.89535916] [0.23787327]\n",
      "80 0.0030669235 [0.93567973] [0.1462151]\n",
      "100 0.0011587694 [0.9604639] [0.08987494]\n",
      "120 0.00043781195 [0.9756981] [0.05524397]\n",
      "140 0.00016541618 [0.9850622] [0.03395713]\n",
      "160 6.249933e-05 [0.9908181] [0.02087266]\n",
      "180 2.3613937e-05 [0.9943561] [0.01282994]\n",
      "200 8.922137e-06 [0.99653083] [0.00788628]\n",
      "220 3.3709982e-06 [0.9978676] [0.00484752]\n",
      "240 1.2734735e-06 [0.9986893] [0.00297965]\n",
      "260 4.8124485e-07 [0.9991943] [0.00183153]\n",
      "280 1.8181804e-07 [0.9995048] [0.00112581]\n",
      "300 6.868365e-08 [0.9996956] [0.00069195]\n",
      "320 2.594733e-08 [0.9998129] [0.00042533]\n",
      "340 9.811104e-09 [0.99988496] [0.00026146]\n",
      "360 3.7085262e-09 [0.9999293] [0.00016069]\n",
      "380 1.4065004e-09 [0.9999565] [9.880333e-05]\n",
      "400 5.299891e-10 [0.9999733] [6.0783503e-05]\n",
      "420 1.9906565e-10 [0.9999836] [3.736285e-05]\n",
      "440 7.596649e-11 [0.9999899] [2.2934551e-05]\n",
      "460 2.8152888e-11 [0.99999386] [1.4061408e-05]\n",
      "480 1.0446162e-11 [0.99999624] [8.593678e-06]\n",
      "500 4.007461e-12 [0.9999977] [5.287607e-06]\n",
      "520 1.4116116e-12 [0.99999857] [3.2332343e-06]\n",
      "540 5.9211896e-13 [0.99999917] [2.005379e-06]\n",
      "560 3.1855998e-13 [0.9999994] [1.2623077e-06]\n",
      "580 9.947598e-14 [0.99999964] [8.053389e-07]\n",
      "600 6.158037e-14 [0.9999997] [6.424197e-07]\n",
      "620 4.8553755e-14 [0.99999976] [5.152632e-07]\n",
      "640 4.2632564e-14 [0.9999999] [3.324756e-07]\n",
      "660 4.7369517e-15 [0.99999994] [1.4968803e-07]\n",
      "680 1.1842379e-15 [1.] [3.0478756e-08]\n",
      "700 0.0 [1.] [2.6505113e-08]\n",
      "720 0.0 [1.] [2.6505113e-08]\n",
      "740 0.0 [1.] [2.6505113e-08]\n",
      "760 0.0 [1.] [2.6505113e-08]\n",
      "780 0.0 [1.] [2.6505113e-08]\n",
      "800 0.0 [1.] [2.6505113e-08]\n",
      "820 0.0 [1.] [2.6505113e-08]\n",
      "840 0.0 [1.] [2.6505113e-08]\n",
      "860 0.0 [1.] [2.6505113e-08]\n",
      "880 0.0 [1.] [2.6505113e-08]\n",
      "900 0.0 [1.] [2.6505113e-08]\n",
      "920 0.0 [1.] [2.6505113e-08]\n",
      "940 0.0 [1.] [2.6505113e-08]\n",
      "960 0.0 [1.] [2.6505113e-08]\n",
      "980 0.0 [1.] [2.6505113e-08]\n",
      "1000 0.0 [1.] [2.6505113e-08]\n",
      "1020 0.0 [1.] [2.6505113e-08]\n",
      "1040 0.0 [1.] [2.6505113e-08]\n",
      "1060 0.0 [1.] [2.6505113e-08]\n",
      "1080 0.0 [1.] [2.6505113e-08]\n",
      "1100 0.0 [1.] [2.6505113e-08]\n",
      "1120 0.0 [1.] [2.6505113e-08]\n",
      "1140 0.0 [1.] [2.6505113e-08]\n",
      "1160 0.0 [1.] [2.6505113e-08]\n",
      "1180 0.0 [1.] [2.6505113e-08]\n",
      "1200 0.0 [1.] [2.6505113e-08]\n",
      "1220 0.0 [1.] [2.6505113e-08]\n",
      "1240 0.0 [1.] [2.6505113e-08]\n",
      "1260 0.0 [1.] [2.6505113e-08]\n",
      "1280 0.0 [1.] [2.6505113e-08]\n",
      "1300 0.0 [1.] [2.6505113e-08]\n",
      "1320 0.0 [1.] [2.6505113e-08]\n",
      "1340 0.0 [1.] [2.6505113e-08]\n",
      "1360 0.0 [1.] [2.6505113e-08]\n",
      "1380 0.0 [1.] [2.6505113e-08]\n",
      "1400 0.0 [1.] [2.6505113e-08]\n",
      "1420 0.0 [1.] [2.6505113e-08]\n",
      "1440 0.0 [1.] [2.6505113e-08]\n",
      "1460 0.0 [1.] [2.6505113e-08]\n",
      "1480 0.0 [1.] [2.6505113e-08]\n",
      "1500 0.0 [1.] [2.6505113e-08]\n",
      "1520 0.0 [1.] [2.6505113e-08]\n",
      "1540 0.0 [1.] [2.6505113e-08]\n",
      "1560 0.0 [1.] [2.6505113e-08]\n",
      "1580 0.0 [1.] [2.6505113e-08]\n",
      "1600 0.0 [1.] [2.6505113e-08]\n",
      "1620 0.0 [1.] [2.6505113e-08]\n",
      "1640 0.0 [1.] [2.6505113e-08]\n",
      "1660 0.0 [1.] [2.6505113e-08]\n",
      "1680 0.0 [1.] [2.6505113e-08]\n",
      "1700 0.0 [1.] [2.6505113e-08]\n",
      "1720 0.0 [1.] [2.6505113e-08]\n",
      "1740 0.0 [1.] [2.6505113e-08]\n",
      "1760 0.0 [1.] [2.6505113e-08]\n",
      "1780 0.0 [1.] [2.6505113e-08]\n",
      "1800 0.0 [1.] [2.6505113e-08]\n",
      "1820 0.0 [1.] [2.6505113e-08]\n",
      "1840 0.0 [1.] [2.6505113e-08]\n",
      "1860 0.0 [1.] [2.6505113e-08]\n",
      "1880 0.0 [1.] [2.6505113e-08]\n",
      "1900 0.0 [1.] [2.6505113e-08]\n",
      "1920 0.0 [1.] [2.6505113e-08]\n",
      "1940 0.0 [1.] [2.6505113e-08]\n",
      "1960 0.0 [1.] [2.6505113e-08]\n",
      "1980 0.0 [1.] [2.6505113e-08]\n",
      "2000 0.0 [1.] [2.6505113e-08]\n"
     ]
    }
   ],
   "source": [
    "## 1. Build graph using TF operations\n",
    "# H(x) = Wx + b\n",
    "\n",
    "X = [1,2,3]\n",
    "Y = [1,2,3]\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "# Our hypothesis Wx+b\n",
    "hypothesis = X*W + b\n",
    "\n",
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis-Y))\n",
    "\n",
    "# GredientDescent(경사하강법)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.1)\n",
    "train = optimizer.minimize(cost)  # cost값을 최소화\n",
    "\n",
    "\n",
    "## 2/3. Run/Update graph and get results\n",
    "\n",
    "# Launch the graph in a session.\n",
    "with tf.Session() as sess:\n",
    "    # Initializes global variables in the graph\n",
    "    sess.run(tf.global_variables_initializer())  # 변수 초기화\n",
    "    \n",
    "    # fit the line\n",
    "    for step in range(2001):  #0~2000\n",
    "        sess.run(train)  #출력X\n",
    "        if step % 20 == 0:\n",
    "            print(step, sess.run(cost), sess.run(W), sess.run(b))\n",
    "            # step(학습 횟수)이 늘어날수록 cost값이 최소가 되는 W,b값을 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 9.596808 [0.2168622] [-1.4648855]\n",
      "20 0.20067693 [1.2796499] [-0.9447097]\n",
      "40 0.10505239 [1.3642007] [-0.85733646]\n",
      "60 0.0947102 [1.3563869] [-0.81295276]\n",
      "80 0.08601103 [1.3405238] [-0.7743573]\n",
      "100 0.0781165 [1.3246047] [-0.7379282]\n",
      "120 0.07094663 [1.3093575] [-0.70324475]\n",
      "140 0.06443491 [1.2948196] [-0.67019457]\n",
      "160 0.05852079 [1.2809643] [-0.63869786]\n",
      "180 0.05314955 [1.2677599] [-0.6086814]\n",
      "200 0.048271254 [1.2551762] [-0.58007544]\n",
      "220 0.043840725 [1.2431839] [-0.5528141]\n",
      "240 0.039816845 [1.2317551] [-0.52683395]\n",
      "260 0.036162313 [1.2208635] [-0.5020748]\n",
      "280 0.0328432 [1.2104838] [-0.47847912]\n",
      "300 0.029828705 [1.2005917] [-0.45599225]\n",
      "320 0.027090916 [1.1911647] [-0.43456233]\n",
      "340 0.02460439 [1.1821808] [-0.41413957]\n",
      "360 0.022346122 [1.1736189] [-0.3946766]\n",
      "380 0.020295098 [1.1654594] [-0.37612817]\n",
      "400 0.018432315 [1.1576834] [-0.35845143]\n",
      "420 0.016740507 [1.1502727] [-0.34160545]\n",
      "440 0.015204019 [1.1432105] [-0.3255512]\n",
      "460 0.013808512 [1.1364802] [-0.31025147]\n",
      "480 0.01254112 [1.1300662] [-0.29567087]\n",
      "500 0.01139006 [1.1239535] [-0.2817755]\n",
      "520 0.010344622 [1.1181281] [-0.26853296]\n",
      "540 0.009395157 [1.1125765] [-0.255913]\n",
      "560 0.008532825 [1.1072859] [-0.24388596]\n",
      "580 0.007749647 [1.1022438] [-0.23242429]\n",
      "600 0.00703836 [1.0974387] [-0.2215012]\n",
      "620 0.006392356 [1.0928595] [-0.21109147]\n",
      "640 0.00580564 [1.0884954] [-0.20117092]\n",
      "660 0.0052727745 [1.0843365] [-0.19171661]\n",
      "680 0.0047888253 [1.0803729] [-0.1827067]\n",
      "700 0.004349276 [1.0765958] [-0.17412011]\n",
      "720 0.0039500836 [1.072996] [-0.16593713]\n",
      "740 0.003587534 [1.0695655] [-0.15813872]\n",
      "760 0.0032582583 [1.0662962] [-0.15070683]\n",
      "780 0.0029592018 [1.0631807] [-0.14362419]\n",
      "800 0.002687589 [1.0602112] [-0.13687435]\n",
      "820 0.0024409143 [1.0573815] [-0.13044178]\n",
      "840 0.002216878 [1.0546849] [-0.12431145]\n",
      "860 0.0020134 [1.0521148] [-0.11846928]\n",
      "880 0.001828607 [1.0496657] [-0.11290172]\n",
      "900 0.001660769 [1.0473316] [-0.10759573]\n",
      "920 0.0015083362 [1.0451071] [-0.10253911]\n",
      "940 0.0013698969 [1.0429873] [-0.09772018]\n",
      "960 0.001244164 [1.0409673] [-0.09312777]\n",
      "980 0.0011299705 [1.0390418] [-0.08875122]\n",
      "1000 0.0010262575 [1.0372069] [-0.08458019]\n",
      "1020 0.00093206455 [1.0354583] [-0.08060523]\n",
      "1040 0.00084651524 [1.033792] [-0.07681708]\n",
      "1060 0.0007688226 [1.0322038] [-0.07320699]\n",
      "1080 0.0006982535 [1.0306906] [-0.06976653]\n",
      "1100 0.00063416484 [1.0292481] [-0.06648776]\n",
      "1120 0.0005759594 [1.0278735] [-0.06336305]\n",
      "1140 0.0005230935 [1.0265635] [-0.06038522]\n",
      "1160 0.00047508182 [1.0253152] [-0.05754731]\n",
      "1180 0.0004314762 [1.0241255] [-0.05484284]\n",
      "1200 0.00039187554 [1.0229917] [-0.05226546]\n",
      "1220 0.00035591074 [1.0219113] [-0.04980918]\n",
      "1240 0.0003232458 [1.0208818] [-0.04746844]\n",
      "1260 0.00029358082 [1.0199006] [-0.04523786]\n",
      "1280 0.00026663244 [1.0189649] [-0.04311181]\n",
      "1300 0.00024215698 [1.0180736] [-0.04108562]\n",
      "1320 0.00021992916 [1.0172242] [-0.03915469]\n",
      "1340 0.00019974505 [1.0164146] [-0.0373145]\n",
      "1360 0.00018141174 [1.0156432] [-0.03556085]\n",
      "1380 0.00016476109 [1.0149081] [-0.03388961]\n",
      "1400 0.00014963858 [1.0142075] [-0.03229692]\n",
      "1420 0.0001359039 [1.0135398] [-0.03077907]\n",
      "1440 0.00012342886 [1.0129035] [-0.02933258]\n",
      "1460 0.000112100475 [1.012297] [-0.02795407]\n",
      "1480 0.00010181055 [1.0117191] [-0.02664033]\n",
      "1500 9.246711e-05 [1.0111684] [-0.02538834]\n",
      "1520 8.39812e-05 [1.0106436] [-0.02419522]\n",
      "1540 7.6272605e-05 [1.0101433] [-0.02305812]\n",
      "1560 6.927243e-05 [1.0096666] [-0.02197441]\n",
      "1580 6.2912586e-05 [1.0092123] [-0.02094167]\n",
      "1600 5.713897e-05 [1.0087793] [-0.01995749]\n",
      "1620 5.1894152e-05 [1.0083667] [-0.01901953]\n",
      "1640 4.713058e-05 [1.0079734] [-0.01812566]\n",
      "1660 4.2804255e-05 [1.0075988] [-0.01727381]\n",
      "1680 3.8876726e-05 [1.0072417] [-0.01646203]\n",
      "1700 3.5308214e-05 [1.0069013] [-0.01568838]\n",
      "1720 3.206782e-05 [1.006577] [-0.01495108]\n",
      "1740 2.9124227e-05 [1.0062679] [-0.01424845]\n",
      "1760 2.6450703e-05 [1.0059733] [-0.01357881]\n",
      "1780 2.4023371e-05 [1.0056927] [-0.0129407]\n",
      "1800 2.181903e-05 [1.0054251] [-0.01233255]\n",
      "1820 1.9815678e-05 [1.0051701] [-0.01175298]\n",
      "1840 1.799725e-05 [1.0049272] [-0.01120063]\n",
      "1860 1.6345353e-05 [1.0046957] [-0.01067426]\n",
      "1880 1.4844919e-05 [1.004475] [-0.01017264]\n",
      "1900 1.3482513e-05 [1.0042647] [-0.00969462]\n",
      "1920 1.224539e-05 [1.0040642] [-0.00923899]\n",
      "1940 1.1121129e-05 [1.0038732] [-0.00880477]\n",
      "1960 1.01007545e-05 [1.0036912] [-0.00839098]\n",
      "1980 9.173799e-06 [1.0035179] [-0.00799667]\n",
      "2000 8.331713e-06 [1.0033525] [-0.00762093]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# X and Y data\n",
    "X = [1,2,3]\n",
    "Y = [1,2,3]\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "# Our hypothesis XW+b\n",
    "hypothesis = X * W + b\n",
    "\n",
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis-Y))\n",
    "\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01) # 학습률 0.01로 경사 하강 train\n",
    "train = optimizer.minimize(cost) #train 한 값에서 최소값\n",
    "\n",
    "# Launch the graph in a session\n",
    "with tf.Session() as sess:\n",
    "    # Initializes global variables in the graph.\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Fit the line\n",
    "    for step in range(2001):\n",
    "        sess.run(train)\n",
    "        if step % 20 == 0:\n",
    "            print(step, sess.run(cost), sess.run(W), sess.run(b))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weights값이 1로 수렴할수록 cost값이 최소가되는 것을 볼 수 있다.\n",
    "\n",
    "cost를 최소화 시키는 weight값은 1으로 최상의 weight값은 1이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#그래프 시각화\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = [1,2,3]\n",
    "Y = [1,2,3]\n",
    "\n",
    "W = tf.placeholder(tf.float32)\n",
    "# Our hypothesis for linear model X * W\n",
    "hypothesis = X*W\n",
    "\n",
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis-Y))\n",
    "\n",
    "# Launch the graph in a session.\n",
    "with tf.Session() as sess:\n",
    "    # Variables for plotting cost function\n",
    "    W_val=[]\n",
    "    cost_val=[]\n",
    "    for i in range(-30, 50):\n",
    "        feed_W = i*0.1\n",
    "        curr_cost, curr_W = sess.run([cost,W], feed_dict= {W:feed_W})\n",
    "        W_val.append(curr_W)\n",
    "        cost_val.append(curr_cost)\n",
    "    \n",
    "    # Show the cost function\n",
    "    plt.plot(W_val,cost_val)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그래프의 x축은 weights값을 y축은 cost값을 나타낸다.\n",
    "\n",
    "그래프를 살펴보아도 W = 1일때 최소값을 갖는 형태를 보인다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5.0\n",
      "1 1.2666664\n",
      "2 1.0177778\n",
      "3 1.0011852\n",
      "4 1.000079\n",
      "5 1.0000052\n",
      "6 1.0000004\n",
      "7 1.0\n",
      "8 1.0\n",
      "9 1.0\n",
      "10 1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# tf Graph input\n",
    "X = [1,2,3]\n",
    "Y = [1,2,3]\n",
    "\n",
    "# Set wrong model weights\n",
    "W = tf.Variable(5.0) # 처음 weights값을 5.0으로 설정\n",
    "\n",
    "# Linear model \n",
    "hypothesis = X*W\n",
    "\n",
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis-Y))\n",
    "\n",
    "# minimizer : Gradient Descent Magic\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session:\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(11):\n",
    "        print(step, sess.run(W))\n",
    "        sess.run(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -3.0\n",
      "1 0.7333336\n",
      "2 0.98222226\n",
      "3 0.9988148\n",
      "4 0.99992096\n",
      "5 0.9999947\n",
      "6 0.99999964\n",
      "7 0.99999994\n",
      "8 1.0\n",
      "9 1.0\n",
      "10 1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# tf Graph Input\n",
    "X = [1,2,3]\n",
    "Y = [1,2,3]\n",
    "\n",
    "# Set wrong model weights\n",
    "W = tf.Variable(-3.0)\n",
    "\n",
    "# Linear model\n",
    "hypothesis = X*W\n",
    "\n",
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis-Y))\n",
    "\n",
    "# Minimize: Granient Descent Magic\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session.\n",
    "with tf.Session() as sess:\n",
    "    # Initializes global variables in the graph.\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(11):\n",
    "        print(step, sess.run(W))\n",
    "        sess.run(train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 2 실습을 살펴보면\n",
    "\n",
    "초기에 잘못된 weight값을 임의로 설정해두고 훈련시킨 모델에 적용하니 기존에 설정했던 weight값이 cost값을 최소로 하는 1에 가깝게 수렴하는 것을 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4.463865 [0.02197009]\n",
      "1 1.2697214 [0.47838408]\n",
      "2 0.3611652 [0.72180486]\n",
      "3 0.10273143 [0.85162926]\n",
      "4 0.029221376 [0.92086893]\n",
      "5 0.0083118705 [0.95779675]\n",
      "6 0.0023642608 [0.9774916]\n",
      "7 0.00067250634 [0.9879955]\n",
      "8 0.00019128692 [0.9935976]\n",
      "9 5.4411954e-05 [0.99658537]\n",
      "10 1.5478015e-05 [0.99817884]\n",
      "11 4.402145e-06 [0.99902874]\n",
      "12 1.2522328e-06 [0.999482]\n",
      "13 3.5614457e-07 [0.99972373]\n",
      "14 1.0131271e-07 [0.99985266]\n",
      "15 2.8781628e-08 [0.99992144]\n",
      "16 8.18866e-09 [0.9999581]\n",
      "17 2.328805e-09 [0.99997765]\n",
      "18 6.6317324e-10 [0.9999881]\n",
      "19 1.8905766e-10 [0.9999936]\n",
      "20 5.4272437e-11 [0.9999966]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x_data = [1,2,3]\n",
    "y_data = [1,2,3]\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), name = 'weight')\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "# Our hypothesis for linear model model X * W\n",
    "hypothesis = X * W\n",
    "\n",
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis-Y))\n",
    "\n",
    "# Minimize : Gradient Descent using derivative: W -= learning_rate * derivative\n",
    "learning_rate = 0.1\n",
    "gradient = tf.reduce_mean((W*X-Y)*X)\n",
    "descent = W - learning_rate * gradient  # 업데이트한 weight\n",
    "update = W.assign(descent)  # W값을 descent값으로 업데이트\n",
    "# optimizer = GradientDescentOptimizer(learning_rate = 0.1)\n",
    "# train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(21):\n",
    "        sess.run(update, feed_dict={X:x_data, Y:y_data})\n",
    "        print(step, sess.run(cost, feed_dict={X:x_data, Y:y_data}), sess.run(W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost: 40464.67 \n",
      "Prediction:\n",
      " [[-27.901814]\n",
      " [-28.779766]\n",
      " [-30.288525]\n",
      " [-38.27154 ]\n",
      " [-16.595356]]\n",
      "10 Cost: 9.505722 \n",
      "Prediction:\n",
      " [[150.03337]\n",
      " [185.07103]\n",
      " [180.42955]\n",
      " [191.19542]\n",
      " [146.51524]]\n",
      "20 Cost: 9.111055 \n",
      "Prediction:\n",
      " [[150.57909]\n",
      " [185.71297]\n",
      " [181.06921]\n",
      " [191.89229]\n",
      " [147.00114]]\n",
      "30 Cost: 9.086856 \n",
      "Prediction:\n",
      " [[150.58804]\n",
      " [185.70978]\n",
      " [181.07327]\n",
      " [191.89697]\n",
      " [146.99501]]\n",
      "40 Cost: 9.062825 \n",
      "Prediction:\n",
      " [[150.59535]\n",
      " [185.70468]\n",
      " [181.07538]\n",
      " [191.89954]\n",
      " [146.98741]]\n",
      "50 Cost: 9.038893 \n",
      "Prediction:\n",
      " [[150.60265]\n",
      " [185.69957]\n",
      " [181.07748]\n",
      " [191.90211]\n",
      " [146.97984]]\n",
      "60 Cost: 9.014977 \n",
      "Prediction:\n",
      " [[150.60992]\n",
      " [185.69447]\n",
      " [181.07957]\n",
      " [191.90472]\n",
      " [146.97227]]\n",
      "70 Cost: 8.991321 \n",
      "Prediction:\n",
      " [[150.61716]\n",
      " [185.6894 ]\n",
      " [181.08163]\n",
      " [191.90724]\n",
      " [146.96472]]\n",
      "80 Cost: 8.967685 \n",
      "Prediction:\n",
      " [[150.62437]\n",
      " [185.68434]\n",
      " [181.0837 ]\n",
      " [191.9098 ]\n",
      " [146.95718]]\n",
      "90 Cost: 8.944195 \n",
      "Prediction:\n",
      " [[150.63158]\n",
      " [185.67929]\n",
      " [181.08578]\n",
      " [191.91237]\n",
      " [146.94968]]\n",
      "100 Cost: 8.920848 \n",
      "Prediction:\n",
      " [[150.63876]\n",
      " [185.67426]\n",
      " [181.08786]\n",
      " [191.9149 ]\n",
      " [146.94218]]\n",
      "110 Cost: 8.8975725 \n",
      "Prediction:\n",
      " [[150.64592]\n",
      " [185.66927]\n",
      " [181.08989]\n",
      " [191.91745]\n",
      " [146.93471]]\n",
      "120 Cost: 8.87443 \n",
      "Prediction:\n",
      " [[150.65305]\n",
      " [185.66422]\n",
      " [181.09192]\n",
      " [191.91995]\n",
      " [146.92723]]\n",
      "130 Cost: 8.851464 \n",
      "Prediction:\n",
      " [[150.66017]\n",
      " [185.65926]\n",
      " [181.09401]\n",
      " [191.92249]\n",
      " [146.91982]]\n",
      "140 Cost: 8.828543 \n",
      "Prediction:\n",
      " [[150.6673 ]\n",
      " [185.65428]\n",
      " [181.09602]\n",
      " [191.925  ]\n",
      " [146.9124 ]]\n",
      "150 Cost: 8.805766 \n",
      "Prediction:\n",
      " [[150.67438]\n",
      " [185.64932]\n",
      " [181.09808]\n",
      " [191.92755]\n",
      " [146.90503]]\n",
      "160 Cost: 8.782976 \n",
      "Prediction:\n",
      " [[150.68143]\n",
      " [185.64436]\n",
      " [181.10008]\n",
      " [191.9301 ]\n",
      " [146.89763]]\n",
      "170 Cost: 8.760457 \n",
      "Prediction:\n",
      " [[150.68848]\n",
      " [185.63943]\n",
      " [181.10213]\n",
      " [191.93259]\n",
      " [146.89027]]\n",
      "180 Cost: 8.738021 \n",
      "Prediction:\n",
      " [[150.6955 ]\n",
      " [185.63454]\n",
      " [181.10416]\n",
      " [191.9351 ]\n",
      " [146.88295]]\n",
      "190 Cost: 8.715619 \n",
      "Prediction:\n",
      " [[150.7025 ]\n",
      " [185.62962]\n",
      " [181.10619]\n",
      " [191.93764]\n",
      " [146.87563]]\n",
      "200 Cost: 8.6934185 \n",
      "Prediction:\n",
      " [[150.70947]\n",
      " [185.62473]\n",
      " [181.10815]\n",
      " [191.9401 ]\n",
      " [146.86832]]\n",
      "210 Cost: 8.671262 \n",
      "Prediction:\n",
      " [[150.71646]\n",
      " [185.61984]\n",
      " [181.11015]\n",
      " [191.94258]\n",
      " [146.86102]]\n",
      "220 Cost: 8.649261 \n",
      "Prediction:\n",
      " [[150.72339]\n",
      " [185.61499]\n",
      " [181.11215]\n",
      " [191.94508]\n",
      " [146.85378]]\n",
      "230 Cost: 8.627337 \n",
      "Prediction:\n",
      " [[150.73032]\n",
      " [185.61015]\n",
      " [181.11414]\n",
      " [191.94757]\n",
      " [146.84653]]\n",
      "240 Cost: 8.605513 \n",
      "Prediction:\n",
      " [[150.73723]\n",
      " [185.6053 ]\n",
      " [181.11613]\n",
      " [191.95007]\n",
      " [146.83931]]\n",
      "250 Cost: 8.583831 \n",
      "Prediction:\n",
      " [[150.7441 ]\n",
      " [185.60048]\n",
      " [181.11806]\n",
      " [191.9525 ]\n",
      " [146.83208]]\n",
      "260 Cost: 8.562204 \n",
      "Prediction:\n",
      " [[150.75096]\n",
      " [185.59567]\n",
      " [181.12006]\n",
      " [191.955  ]\n",
      " [146.82489]]\n",
      "270 Cost: 8.540741 \n",
      "Prediction:\n",
      " [[150.75781]\n",
      " [185.5909 ]\n",
      " [181.12202]\n",
      " [191.95747]\n",
      " [146.81773]]\n",
      "280 Cost: 8.519304 \n",
      "Prediction:\n",
      " [[150.76462]\n",
      " [185.58609]\n",
      " [181.12398]\n",
      " [191.95993]\n",
      " [146.81055]]\n",
      "290 Cost: 8.497983 \n",
      "Prediction:\n",
      " [[150.77142]\n",
      " [185.58131]\n",
      " [181.12592]\n",
      " [191.9624 ]\n",
      " [146.8034 ]]\n",
      "300 Cost: 8.476889 \n",
      "Prediction:\n",
      " [[150.77818]\n",
      " [185.57658]\n",
      " [181.12788]\n",
      " [191.96481]\n",
      " [146.79628]]\n",
      "310 Cost: 8.455767 \n",
      "Prediction:\n",
      " [[150.78496]\n",
      " [185.57184]\n",
      " [181.12979]\n",
      " [191.96729]\n",
      " [146.78918]]\n",
      "320 Cost: 8.434802 \n",
      "Prediction:\n",
      " [[150.79169]\n",
      " [185.56711]\n",
      " [181.13171]\n",
      " [191.96971]\n",
      " [146.78209]]\n",
      "330 Cost: 8.413898 \n",
      "Prediction:\n",
      " [[150.79839]\n",
      " [185.56236]\n",
      " [181.13362]\n",
      " [191.97215]\n",
      " [146.77501]]\n",
      "340 Cost: 8.393145 \n",
      "Prediction:\n",
      " [[150.80511]\n",
      " [185.55768]\n",
      " [181.13556]\n",
      " [191.9746 ]\n",
      " [146.76797]]\n",
      "350 Cost: 8.372461 \n",
      "Prediction:\n",
      " [[150.8118 ]\n",
      " [185.55301]\n",
      " [181.13748]\n",
      " [191.97704]\n",
      " [146.76094]]\n",
      "360 Cost: 8.351894 \n",
      "Prediction:\n",
      " [[150.81845]\n",
      " [185.54831]\n",
      " [181.13937]\n",
      " [191.97943]\n",
      " [146.7539 ]]\n",
      "370 Cost: 8.331401 \n",
      "Prediction:\n",
      " [[150.8251 ]\n",
      " [185.54366]\n",
      " [181.14127]\n",
      " [191.98187]\n",
      " [146.74692]]\n",
      "380 Cost: 8.3110485 \n",
      "Prediction:\n",
      " [[150.83174]\n",
      " [185.53902]\n",
      " [181.14317]\n",
      " [191.98427]\n",
      " [146.73993]]\n",
      "390 Cost: 8.290754 \n",
      "Prediction:\n",
      " [[150.83833]\n",
      " [185.53436]\n",
      " [181.14505]\n",
      " [191.98668]\n",
      " [146.73296]]\n",
      "400 Cost: 8.270583 \n",
      "Prediction:\n",
      " [[150.84496]\n",
      " [185.52977]\n",
      " [181.14696]\n",
      " [191.9891 ]\n",
      " [146.72603]]\n",
      "410 Cost: 8.250493 \n",
      "Prediction:\n",
      " [[150.85149]\n",
      " [185.52513]\n",
      " [181.14882]\n",
      " [191.9915 ]\n",
      " [146.71909]]\n",
      "420 Cost: 8.230505 \n",
      "Prediction:\n",
      " [[150.85806]\n",
      " [185.52057]\n",
      " [181.15073]\n",
      " [191.99393]\n",
      " [146.71219]]\n",
      "430 Cost: 8.210601 \n",
      "Prediction:\n",
      " [[150.8646 ]\n",
      " [185.51598]\n",
      " [181.15257]\n",
      " [191.99632]\n",
      " [146.70529]]\n",
      "440 Cost: 8.190821 \n",
      "Prediction:\n",
      " [[150.87112]\n",
      " [185.5114 ]\n",
      " [181.15445]\n",
      " [191.99872]\n",
      " [146.69843]]\n",
      "450 Cost: 8.171183 \n",
      "Prediction:\n",
      " [[150.8776 ]\n",
      " [185.50684]\n",
      " [181.15631]\n",
      " [192.00107]\n",
      " [146.69156]]\n",
      "460 Cost: 8.151542 \n",
      "Prediction:\n",
      " [[150.88411]\n",
      " [185.50233]\n",
      " [181.15816]\n",
      " [192.0035 ]\n",
      " [146.68474]]\n",
      "470 Cost: 8.132042 \n",
      "Prediction:\n",
      " [[150.89053]\n",
      " [185.49777]\n",
      " [181.16   ]\n",
      " [192.00584]\n",
      " [146.67789]]\n",
      "480 Cost: 8.112684 \n",
      "Prediction:\n",
      " [[150.89699]\n",
      " [185.49326]\n",
      " [181.16182]\n",
      " [192.0082 ]\n",
      " [146.6711 ]]\n",
      "490 Cost: 8.093334 \n",
      "Prediction:\n",
      " [[150.90338]\n",
      " [185.48872]\n",
      " [181.16367]\n",
      " [192.01057]\n",
      " [146.66429]]\n",
      "500 Cost: 8.07414 \n",
      "Prediction:\n",
      " [[150.90979]\n",
      " [185.48425]\n",
      " [181.1655 ]\n",
      " [192.01294]\n",
      " [146.65753]]\n",
      "510 Cost: 8.054979 \n",
      "Prediction:\n",
      " [[150.91618]\n",
      " [185.47977]\n",
      " [181.1673 ]\n",
      " [192.0153 ]\n",
      " [146.65077]]\n",
      "520 Cost: 8.035924 \n",
      "Prediction:\n",
      " [[150.92255]\n",
      " [185.47531]\n",
      " [181.16913]\n",
      " [192.01765]\n",
      " [146.64401]]\n",
      "530 Cost: 8.016916 \n",
      "Prediction:\n",
      " [[150.92888]\n",
      " [185.47086]\n",
      " [181.17093]\n",
      " [192.02002]\n",
      " [146.63727]]\n",
      "540 Cost: 7.9980917 \n",
      "Prediction:\n",
      " [[150.9352 ]\n",
      " [185.46635]\n",
      " [181.1727 ]\n",
      " [192.02232]\n",
      " [146.63055]]\n",
      "550 Cost: 7.9793167 \n",
      "Prediction:\n",
      " [[150.9415 ]\n",
      " [185.46194]\n",
      " [181.17451]\n",
      " [192.02469]\n",
      " [146.62387]]\n",
      "560 Cost: 7.96066 \n",
      "Prediction:\n",
      " [[150.9478 ]\n",
      " [185.45755]\n",
      " [181.17632]\n",
      " [192.02702]\n",
      " [146.6172 ]]\n",
      "570 Cost: 7.9420815 \n",
      "Prediction:\n",
      " [[150.95407]\n",
      " [185.45316]\n",
      " [181.1781 ]\n",
      " [192.02936]\n",
      " [146.61055]]\n",
      "580 Cost: 7.9235864 \n",
      "Prediction:\n",
      " [[150.96033]\n",
      " [185.44875]\n",
      " [181.1799 ]\n",
      " [192.0317 ]\n",
      " [146.60391]]\n",
      "590 Cost: 7.905207 \n",
      "Prediction:\n",
      " [[150.96658]\n",
      " [185.44437]\n",
      " [181.18167]\n",
      " [192.03401]\n",
      " [146.5973 ]]\n",
      "600 Cost: 7.8868637 \n",
      "Prediction:\n",
      " [[150.97281]\n",
      " [185.44   ]\n",
      " [181.18344]\n",
      " [192.03635]\n",
      " [146.5907 ]]\n",
      "610 Cost: 7.8686266 \n",
      "Prediction:\n",
      " [[150.979  ]\n",
      " [185.43565]\n",
      " [181.18521]\n",
      " [192.03865]\n",
      " [146.58409]]\n",
      "620 Cost: 7.8505096 \n",
      "Prediction:\n",
      " [[150.98518]\n",
      " [185.43134]\n",
      " [181.18698]\n",
      " [192.04099]\n",
      " [146.57755]]\n",
      "630 Cost: 7.8324127 \n",
      "Prediction:\n",
      " [[150.99133]\n",
      " [185.42697]\n",
      " [181.18872]\n",
      " [192.04327]\n",
      " [146.57095]]\n",
      "640 Cost: 7.8144593 \n",
      "Prediction:\n",
      " [[150.99748]\n",
      " [185.42265]\n",
      " [181.19048]\n",
      " [192.04556]\n",
      " [146.5644 ]]\n",
      "650 Cost: 7.796561 \n",
      "Prediction:\n",
      " [[151.0036 ]\n",
      " [185.41833]\n",
      " [181.19221]\n",
      " [192.04788]\n",
      " [146.55789]]\n",
      "660 Cost: 7.7787757 \n",
      "Prediction:\n",
      " [[151.00972]\n",
      " [185.41405]\n",
      " [181.19394]\n",
      " [192.05016]\n",
      " [146.55138]]\n",
      "670 Cost: 7.761064 \n",
      "Prediction:\n",
      " [[151.01584]\n",
      " [185.40977]\n",
      " [181.19571]\n",
      " [192.05246]\n",
      " [146.54489]]\n",
      "680 Cost: 7.7434263 \n",
      "Prediction:\n",
      " [[151.02188]\n",
      " [185.4055 ]\n",
      " [181.19739]\n",
      " [192.05472]\n",
      " [146.53839]]\n",
      "690 Cost: 7.72585 \n",
      "Prediction:\n",
      " [[151.02794]\n",
      " [185.40125]\n",
      " [181.19914]\n",
      " [192.05704]\n",
      " [146.53194]]\n",
      "700 Cost: 7.7084084 \n",
      "Prediction:\n",
      " [[151.034  ]\n",
      " [185.39702]\n",
      " [181.20087]\n",
      " [192.05933]\n",
      " [146.52551]]\n",
      "710 Cost: 7.6909966 \n",
      "Prediction:\n",
      " [[151.04002]\n",
      " [185.39278]\n",
      " [181.20256]\n",
      " [192.06158]\n",
      " [146.51906]]\n",
      "720 Cost: 7.67371 \n",
      "Prediction:\n",
      " [[151.04602]\n",
      " [185.38855]\n",
      " [181.20427]\n",
      " [192.06387]\n",
      " [146.51266]]\n",
      "730 Cost: 7.656459 \n",
      "Prediction:\n",
      " [[151.05197]\n",
      " [185.38434]\n",
      " [181.20595]\n",
      " [192.06612]\n",
      " [146.50623]]\n",
      "740 Cost: 7.6393614 \n",
      "Prediction:\n",
      " [[151.05797]\n",
      " [185.38014]\n",
      " [181.20766]\n",
      " [192.06837]\n",
      " [146.49986]]\n",
      "750 Cost: 7.6223 \n",
      "Prediction:\n",
      " [[151.06393]\n",
      " [185.37593]\n",
      " [181.20934]\n",
      " [192.07063]\n",
      " [146.4935 ]]\n",
      "760 Cost: 7.605283 \n",
      "Prediction:\n",
      " [[151.06987]\n",
      " [185.37178]\n",
      " [181.21103]\n",
      " [192.0729 ]\n",
      " [146.48714]]\n",
      "770 Cost: 7.5884323 \n",
      "Prediction:\n",
      " [[151.07578]\n",
      " [185.3676 ]\n",
      " [181.2127 ]\n",
      " [192.07513]\n",
      " [146.4808 ]]\n",
      "780 Cost: 7.5716124 \n",
      "Prediction:\n",
      " [[151.08171]\n",
      " [185.36348]\n",
      " [181.2144 ]\n",
      " [192.07742]\n",
      " [146.47452]]\n",
      "790 Cost: 7.5548964 \n",
      "Prediction:\n",
      " [[151.08757]\n",
      " [185.35931]\n",
      " [181.21605]\n",
      " [192.07964]\n",
      " [146.4682 ]]\n",
      "800 Cost: 7.538255 \n",
      "Prediction:\n",
      " [[151.09344]\n",
      " [185.35522]\n",
      " [181.21774]\n",
      " [192.08188]\n",
      " [146.46191]]\n",
      "810 Cost: 7.5216002 \n",
      "Prediction:\n",
      " [[151.09929]\n",
      " [185.35109]\n",
      " [181.21938]\n",
      " [192.08412]\n",
      " [146.45561]]\n",
      "820 Cost: 7.5052147 \n",
      "Prediction:\n",
      " [[151.10512]\n",
      " [185.34698]\n",
      " [181.22104]\n",
      " [192.0863 ]\n",
      " [146.44937]]\n",
      "830 Cost: 7.488748 \n",
      "Prediction:\n",
      " [[151.11095]\n",
      " [185.34288]\n",
      " [181.2227 ]\n",
      " [192.08856]\n",
      " [146.44313]]\n",
      "840 Cost: 7.472417 \n",
      "Prediction:\n",
      " [[151.11674]\n",
      " [185.33884]\n",
      " [181.22437]\n",
      " [192.0908 ]\n",
      " [146.43692]]\n",
      "850 Cost: 7.456107 \n",
      "Prediction:\n",
      " [[151.12253]\n",
      " [185.33475]\n",
      " [181.22595]\n",
      " [192.09302]\n",
      " [146.4307 ]]\n",
      "860 Cost: 7.439986 \n",
      "Prediction:\n",
      " [[151.12828]\n",
      " [185.33066]\n",
      " [181.22762]\n",
      " [192.0952 ]\n",
      " [146.4245 ]]\n",
      "870 Cost: 7.4238386 \n",
      "Prediction:\n",
      " [[151.13406]\n",
      " [185.32664]\n",
      " [181.22923]\n",
      " [192.09744]\n",
      " [146.41833]]\n",
      "880 Cost: 7.4078217 \n",
      "Prediction:\n",
      " [[151.13977]\n",
      " [185.32262]\n",
      " [181.23085]\n",
      " [192.09962]\n",
      " [146.41216]]\n",
      "890 Cost: 7.391847 \n",
      "Prediction:\n",
      " [[151.14548]\n",
      " [185.31857]\n",
      " [181.23247]\n",
      " [192.10184]\n",
      " [146.406  ]]\n",
      "900 Cost: 7.375978 \n",
      "Prediction:\n",
      " [[151.15118]\n",
      " [185.31458]\n",
      " [181.23405]\n",
      " [192.10403]\n",
      " [146.39989]]\n",
      "910 Cost: 7.3601274 \n",
      "Prediction:\n",
      " [[151.15688]\n",
      " [185.31055]\n",
      " [181.2357 ]\n",
      " [192.10625]\n",
      " [146.39375]]\n",
      "920 Cost: 7.3444533 \n",
      "Prediction:\n",
      " [[151.16254]\n",
      " [185.30658]\n",
      " [181.23729]\n",
      " [192.10841]\n",
      " [146.38766]]\n",
      "930 Cost: 7.328743 \n",
      "Prediction:\n",
      " [[151.1682 ]\n",
      " [185.3026 ]\n",
      " [181.23888]\n",
      " [192.11063]\n",
      " [146.38158]]\n",
      "940 Cost: 7.313161 \n",
      "Prediction:\n",
      " [[151.1738 ]\n",
      " [185.29861]\n",
      " [181.24046]\n",
      " [192.1128 ]\n",
      " [146.37549]]\n",
      "950 Cost: 7.2976904 \n",
      "Prediction:\n",
      " [[151.17944]\n",
      " [185.29468]\n",
      " [181.24207]\n",
      " [192.11494]\n",
      " [146.36943]]\n",
      "960 Cost: 7.2822037 \n",
      "Prediction:\n",
      " [[151.18503]\n",
      " [185.29074]\n",
      " [181.24365]\n",
      " [192.11717]\n",
      " [146.3634 ]]\n",
      "970 Cost: 7.2668457 \n",
      "Prediction:\n",
      " [[151.19061]\n",
      " [185.2868 ]\n",
      " [181.24524]\n",
      " [192.11932]\n",
      " [146.35736]]\n",
      "980 Cost: 7.2515335 \n",
      "Prediction:\n",
      " [[151.19618]\n",
      " [185.28288]\n",
      " [181.24678]\n",
      " [192.12148]\n",
      " [146.35133]]\n",
      "990 Cost: 7.2363234 \n",
      "Prediction:\n",
      " [[151.20175]\n",
      " [185.27898]\n",
      " [181.24838]\n",
      " [192.12367]\n",
      " [146.34537]]\n",
      "1000 Cost: 7.2211733 \n",
      "Prediction:\n",
      " [[151.20728]\n",
      " [185.27504]\n",
      " [181.24992]\n",
      " [192.12581]\n",
      " [146.33937]]\n",
      "1010 Cost: 7.2060595 \n",
      "Prediction:\n",
      " [[151.21277]\n",
      " [185.27118]\n",
      " [181.25148]\n",
      " [192.12796]\n",
      " [146.33337]]\n",
      "1020 Cost: 7.19104 \n",
      "Prediction:\n",
      " [[151.21829]\n",
      " [185.26732]\n",
      " [181.25305]\n",
      " [192.13016]\n",
      " [146.32745]]\n",
      "1030 Cost: 7.176123 \n",
      "Prediction:\n",
      " [[151.22379]\n",
      " [185.26346]\n",
      " [181.25461]\n",
      " [192.13228]\n",
      " [146.3215 ]]\n",
      "1040 Cost: 7.1612844 \n",
      "Prediction:\n",
      " [[151.22926]\n",
      " [185.25958]\n",
      " [181.25613]\n",
      " [192.13441]\n",
      " [146.3156 ]]\n",
      "1050 Cost: 7.146428 \n",
      "Prediction:\n",
      " [[151.2347 ]\n",
      " [185.25575]\n",
      " [181.25768]\n",
      " [192.13655]\n",
      " [146.30965]]\n",
      "1060 Cost: 7.1317024 \n",
      "Prediction:\n",
      " [[151.24014]\n",
      " [185.25188]\n",
      " [181.25917]\n",
      " [192.13867]\n",
      " [146.30376]]\n",
      "1070 Cost: 7.1170397 \n",
      "Prediction:\n",
      " [[151.24556]\n",
      " [185.2481 ]\n",
      " [181.26073]\n",
      " [192.14082]\n",
      " [146.29788]]\n",
      "1080 Cost: 7.1024055 \n",
      "Prediction:\n",
      " [[151.25098]\n",
      " [185.24431]\n",
      " [181.26227]\n",
      " [192.14299]\n",
      " [146.29202]]\n",
      "1090 Cost: 7.0879226 \n",
      "Prediction:\n",
      " [[151.2564 ]\n",
      " [185.2405 ]\n",
      " [181.26381]\n",
      " [192.1451 ]\n",
      " [146.28618]]\n",
      "1100 Cost: 7.0734167 \n",
      "Prediction:\n",
      " [[151.26175]\n",
      " [185.23671]\n",
      " [181.26529]\n",
      " [192.14723]\n",
      " [146.28033]]\n",
      "1110 Cost: 7.0590544 \n",
      "Prediction:\n",
      " [[151.2671 ]\n",
      " [185.23293]\n",
      " [181.2668 ]\n",
      " [192.1493 ]\n",
      " [146.27449]]\n",
      "1120 Cost: 7.04469 \n",
      "Prediction:\n",
      " [[151.27246]\n",
      " [185.22916]\n",
      " [181.26831]\n",
      " [192.15147]\n",
      " [146.2687 ]]\n",
      "1130 Cost: 7.030431 \n",
      "Prediction:\n",
      " [[151.27777]\n",
      " [185.22539]\n",
      " [181.2698 ]\n",
      " [192.15356]\n",
      " [146.2629 ]]\n",
      "1140 Cost: 7.0163145 \n",
      "Prediction:\n",
      " [[151.28308]\n",
      " [185.22165]\n",
      " [181.27132]\n",
      " [192.15564]\n",
      " [146.25713]]\n",
      "1150 Cost: 7.002122 \n",
      "Prediction:\n",
      " [[151.28839]\n",
      " [185.21793]\n",
      " [181.2728 ]\n",
      " [192.15776]\n",
      " [146.25134]]\n",
      "1160 Cost: 6.9881005 \n",
      "Prediction:\n",
      " [[151.29366]\n",
      " [185.21416]\n",
      " [181.27429]\n",
      " [192.15984]\n",
      " [146.24559]]\n",
      "1170 Cost: 6.9740324 \n",
      "Prediction:\n",
      " [[151.29893]\n",
      " [185.21048]\n",
      " [181.27576]\n",
      " [192.16197]\n",
      " [146.23985]]\n",
      "1180 Cost: 6.960115 \n",
      "Prediction:\n",
      " [[151.30421]\n",
      " [185.20677]\n",
      " [181.27727]\n",
      " [192.16408]\n",
      " [146.23415]]\n",
      "1190 Cost: 6.946292 \n",
      "Prediction:\n",
      " [[151.30943]\n",
      " [185.2031 ]\n",
      " [181.27872]\n",
      " [192.16615]\n",
      " [146.22845]]\n",
      "1200 Cost: 6.9324164 \n",
      "Prediction:\n",
      " [[151.31464]\n",
      " [185.19939]\n",
      " [181.2802 ]\n",
      " [192.16824]\n",
      " [146.22272]]\n",
      "1210 Cost: 6.91875 \n",
      "Prediction:\n",
      " [[151.31984]\n",
      " [185.1957 ]\n",
      " [181.28163]\n",
      " [192.17029]\n",
      " [146.21706]]\n",
      "1220 Cost: 6.90505 \n",
      "Prediction:\n",
      " [[151.32504]\n",
      " [185.19206]\n",
      " [181.28311]\n",
      " [192.1724 ]\n",
      " [146.2114 ]]\n",
      "1230 Cost: 6.89142 \n",
      "Prediction:\n",
      " [[151.33022]\n",
      " [185.18843]\n",
      " [181.28456]\n",
      " [192.17447]\n",
      " [146.20573]]\n",
      "1240 Cost: 6.877866 \n",
      "Prediction:\n",
      " [[151.33539]\n",
      " [185.18475]\n",
      " [181.28601]\n",
      " [192.17651]\n",
      " [146.20007]]\n",
      "1250 Cost: 6.8643827 \n",
      "Prediction:\n",
      " [[151.34053]\n",
      " [185.1811 ]\n",
      " [181.28741]\n",
      " [192.17857]\n",
      " [146.19446]]\n",
      "1260 Cost: 6.8509507 \n",
      "Prediction:\n",
      " [[151.34564]\n",
      " [185.17752]\n",
      " [181.28888]\n",
      " [192.18065]\n",
      " [146.18884]]\n",
      "1270 Cost: 6.8375688 \n",
      "Prediction:\n",
      " [[151.35078]\n",
      " [185.17392]\n",
      " [181.29034]\n",
      " [192.18274]\n",
      " [146.18326]]\n",
      "1280 Cost: 6.8242173 \n",
      "Prediction:\n",
      " [[151.3559 ]\n",
      " [185.17032]\n",
      " [181.29175]\n",
      " [192.18481]\n",
      " [146.17767]]\n",
      "1290 Cost: 6.8110046 \n",
      "Prediction:\n",
      " [[151.36095]\n",
      " [185.1667 ]\n",
      " [181.29315]\n",
      " [192.18683]\n",
      " [146.17209]]\n",
      "1300 Cost: 6.7978373 \n",
      "Prediction:\n",
      " [[151.36603]\n",
      " [185.16315]\n",
      " [181.29459]\n",
      " [192.18887]\n",
      " [146.16653]]\n",
      "1310 Cost: 6.784715 \n",
      "Prediction:\n",
      " [[151.3711 ]\n",
      " [185.1596 ]\n",
      " [181.29604]\n",
      " [192.19093]\n",
      " [146.161  ]]\n",
      "1320 Cost: 6.771638 \n",
      "Prediction:\n",
      " [[151.37613]\n",
      " [185.156  ]\n",
      " [181.29745]\n",
      " [192.193  ]\n",
      " [146.15547]]\n",
      "1330 Cost: 6.75862 \n",
      "Prediction:\n",
      " [[151.3811 ]\n",
      " [185.15244]\n",
      " [181.29881]\n",
      " [192.195  ]\n",
      " [146.14993]]\n",
      "1340 Cost: 6.745659 \n",
      "Prediction:\n",
      " [[151.38615]\n",
      " [185.14891]\n",
      " [181.30025]\n",
      " [192.19705]\n",
      " [146.14442]]\n",
      "1350 Cost: 6.7327666 \n",
      "Prediction:\n",
      " [[151.39116]\n",
      " [185.14542]\n",
      " [181.30164]\n",
      " [192.1991 ]\n",
      " [146.13895]]\n",
      "1360 Cost: 6.7199583 \n",
      "Prediction:\n",
      " [[151.39613]\n",
      " [185.14189]\n",
      " [181.30302]\n",
      " [192.20113]\n",
      " [146.13348]]\n",
      "1370 Cost: 6.707231 \n",
      "Prediction:\n",
      " [[151.40108]\n",
      " [185.13837]\n",
      " [181.30441]\n",
      " [192.20311]\n",
      " [146.128  ]]\n",
      "1380 Cost: 6.6945176 \n",
      "Prediction:\n",
      " [[151.40605]\n",
      " [185.13487]\n",
      " [181.30582]\n",
      " [192.20515]\n",
      " [146.12257]]\n",
      "1390 Cost: 6.6818147 \n",
      "Prediction:\n",
      " [[151.41098]\n",
      " [185.1314 ]\n",
      " [181.3072 ]\n",
      " [192.20721]\n",
      " [146.11714]]\n",
      "1400 Cost: 6.6692247 \n",
      "Prediction:\n",
      " [[151.41591]\n",
      " [185.12791]\n",
      " [181.30858]\n",
      " [192.20921]\n",
      " [146.11171]]\n",
      "1410 Cost: 6.6566877 \n",
      "Prediction:\n",
      " [[151.4208 ]\n",
      " [185.12445]\n",
      " [181.30994]\n",
      " [192.21121]\n",
      " [146.1063 ]]\n",
      "1420 Cost: 6.644197 \n",
      "Prediction:\n",
      " [[151.42572]\n",
      " [185.12102]\n",
      " [181.31133]\n",
      " [192.21324]\n",
      " [146.1009 ]]\n",
      "1430 Cost: 6.631807 \n",
      "Prediction:\n",
      " [[151.43057]\n",
      " [185.11752]\n",
      " [181.31265]\n",
      " [192.21521]\n",
      " [146.09552]]\n",
      "1440 Cost: 6.619439 \n",
      "Prediction:\n",
      " [[151.43544]\n",
      " [185.11409]\n",
      " [181.31401]\n",
      " [192.21721]\n",
      " [146.09015]]\n",
      "1450 Cost: 6.607071 \n",
      "Prediction:\n",
      " [[151.44029]\n",
      " [185.11064]\n",
      " [181.31535]\n",
      " [192.21922]\n",
      " [146.08478]]\n",
      "1460 Cost: 6.594864 \n",
      "Prediction:\n",
      " [[151.44513]\n",
      " [185.10727]\n",
      " [181.31671]\n",
      " [192.22119]\n",
      " [146.07944]]\n",
      "1470 Cost: 6.5826783 \n",
      "Prediction:\n",
      " [[151.44997]\n",
      " [185.10385]\n",
      " [181.3181 ]\n",
      " [192.22319]\n",
      " [146.07411]]\n",
      "1480 Cost: 6.5705237 \n",
      "Prediction:\n",
      " [[151.45477]\n",
      " [185.10043]\n",
      " [181.3194 ]\n",
      " [192.22516]\n",
      " [146.06879]]\n",
      "1490 Cost: 6.558397 \n",
      "Prediction:\n",
      " [[151.45958]\n",
      " [185.09706]\n",
      " [181.32077]\n",
      " [192.22719]\n",
      " [146.06349]]\n",
      "1500 Cost: 6.5463514 \n",
      "Prediction:\n",
      " [[151.46436]\n",
      " [185.09372]\n",
      " [181.3221 ]\n",
      " [192.22919]\n",
      " [146.05821]]\n",
      "1510 Cost: 6.5344377 \n",
      "Prediction:\n",
      " [[151.4691 ]\n",
      " [185.0903 ]\n",
      " [181.32344]\n",
      " [192.23112]\n",
      " [146.05293]]\n",
      "1520 Cost: 6.5224457 \n",
      "Prediction:\n",
      " [[151.47386]\n",
      " [185.08694]\n",
      " [181.32472]\n",
      " [192.2331 ]\n",
      " [146.04764]]\n",
      "1530 Cost: 6.510592 \n",
      "Prediction:\n",
      " [[151.47862]\n",
      " [185.08362]\n",
      " [181.32607]\n",
      " [192.23509]\n",
      " [146.04242]]\n",
      "1540 Cost: 6.4987383 \n",
      "Prediction:\n",
      " [[151.48334]\n",
      " [185.08025]\n",
      " [181.3274 ]\n",
      " [192.23708]\n",
      " [146.03717]]\n",
      "1550 Cost: 6.486964 \n",
      "Prediction:\n",
      " [[151.48802]\n",
      " [185.07692]\n",
      " [181.32867]\n",
      " [192.23901]\n",
      " [146.03192]]\n",
      "1560 Cost: 6.475232 \n",
      "Prediction:\n",
      " [[151.49274]\n",
      " [185.07362]\n",
      " [181.32999]\n",
      " [192.241  ]\n",
      " [146.02672]]\n",
      "1570 Cost: 6.463627 \n",
      "Prediction:\n",
      " [[151.49745]\n",
      " [185.0703 ]\n",
      " [181.33131]\n",
      " [192.24294]\n",
      " [146.02153]]\n",
      "1580 Cost: 6.451991 \n",
      "Prediction:\n",
      " [[151.5021 ]\n",
      " [185.06702]\n",
      " [181.33264]\n",
      " [192.2449 ]\n",
      " [146.01633]]\n",
      "1590 Cost: 6.440445 \n",
      "Prediction:\n",
      " [[151.50674]\n",
      " [185.0637 ]\n",
      " [181.33391]\n",
      " [192.24684]\n",
      " [146.01115]]\n",
      "1600 Cost: 6.4289427 \n",
      "Prediction:\n",
      " [[151.5114 ]\n",
      " [185.06042]\n",
      " [181.3352 ]\n",
      " [192.24881]\n",
      " [146.00601]]\n",
      "1610 Cost: 6.4175096 \n",
      "Prediction:\n",
      " [[151.516  ]\n",
      " [185.05714]\n",
      " [181.33649]\n",
      " [192.25072]\n",
      " [146.00084]]\n",
      "1620 Cost: 6.406044 \n",
      "Prediction:\n",
      " [[151.5206 ]\n",
      " [185.05383]\n",
      " [181.33774]\n",
      " [192.25267]\n",
      " [145.99568]]\n",
      "1630 Cost: 6.394722 \n",
      "Prediction:\n",
      " [[151.52522]\n",
      " [185.05064]\n",
      " [181.33904]\n",
      " [192.25462]\n",
      " [145.99059]]\n",
      "1640 Cost: 6.3834133 \n",
      "Prediction:\n",
      " [[151.5298 ]\n",
      " [185.04738]\n",
      " [181.3403 ]\n",
      " [192.25655]\n",
      " [145.98546]]\n",
      "1650 Cost: 6.3721285 \n",
      "Prediction:\n",
      " [[151.53433]\n",
      " [185.04408]\n",
      " [181.34155]\n",
      " [192.25845]\n",
      " [145.98032]]\n",
      "1660 Cost: 6.3609495 \n",
      "Prediction:\n",
      " [[151.53893]\n",
      " [185.04091]\n",
      " [181.34283]\n",
      " [192.26038]\n",
      " [145.97523]]\n",
      "1670 Cost: 6.3497987 \n",
      "Prediction:\n",
      " [[151.54347]\n",
      " [185.03769]\n",
      " [181.3441 ]\n",
      " [192.26233]\n",
      " [145.97018]]\n",
      "1680 Cost: 6.3387437 \n",
      "Prediction:\n",
      " [[151.548  ]\n",
      " [185.03447]\n",
      " [181.34537]\n",
      " [192.26424]\n",
      " [145.96513]]\n",
      "1690 Cost: 6.327605 \n",
      "Prediction:\n",
      " [[151.55252]\n",
      " [185.03125]\n",
      " [181.3466 ]\n",
      " [192.26617]\n",
      " [145.96005]]\n",
      "1700 Cost: 6.3166246 \n",
      "Prediction:\n",
      " [[151.55705]\n",
      " [185.02806]\n",
      " [181.34787]\n",
      " [192.2681 ]\n",
      " [145.95503]]\n",
      "1710 Cost: 6.3056726 \n",
      "Prediction:\n",
      " [[151.56152]\n",
      " [185.02493]\n",
      " [181.34912]\n",
      " [192.27002]\n",
      " [145.95001]]\n",
      "1720 Cost: 6.2947793 \n",
      "Prediction:\n",
      " [[151.566  ]\n",
      " [185.02171]\n",
      " [181.35036]\n",
      " [192.2719 ]\n",
      " [145.94498]]\n",
      "1730 Cost: 6.2839036 \n",
      "Prediction:\n",
      " [[151.5705 ]\n",
      " [185.0186 ]\n",
      " [181.35162]\n",
      " [192.27383]\n",
      " [145.93999]]\n",
      "1740 Cost: 6.2730875 \n",
      "Prediction:\n",
      " [[151.57494]\n",
      " [185.01541]\n",
      " [181.35281]\n",
      " [192.27571]\n",
      " [145.93498]]\n",
      "1750 Cost: 6.262324 \n",
      "Prediction:\n",
      " [[151.57936]\n",
      " [185.01227]\n",
      " [181.35405]\n",
      " [192.2776 ]\n",
      " [145.93   ]]\n",
      "1760 Cost: 6.2515306 \n",
      "Prediction:\n",
      " [[151.5838 ]\n",
      " [185.00914]\n",
      " [181.35527]\n",
      " [192.27956]\n",
      " [145.92503]]\n",
      "1770 Cost: 6.24096 \n",
      "Prediction:\n",
      " [[151.5882 ]\n",
      " [185.00601]\n",
      " [181.3565 ]\n",
      " [192.2814 ]\n",
      " [145.92009]]\n",
      "1780 Cost: 6.2302794 \n",
      "Prediction:\n",
      " [[151.59259]\n",
      " [185.00288]\n",
      " [181.35771]\n",
      " [192.2833 ]\n",
      " [145.91512]]\n",
      "1790 Cost: 6.2197127 \n",
      "Prediction:\n",
      " [[151.59698]\n",
      " [184.99979]\n",
      " [181.35895]\n",
      " [192.2852 ]\n",
      " [145.9102 ]]\n",
      "1800 Cost: 6.209161 \n",
      "Prediction:\n",
      " [[151.60136]\n",
      " [184.99667]\n",
      " [181.36012]\n",
      " [192.2871 ]\n",
      " [145.90529]]\n",
      "1810 Cost: 6.1986756 \n",
      "Prediction:\n",
      " [[151.60571]\n",
      " [184.99355]\n",
      " [181.36133]\n",
      " [192.28896]\n",
      " [145.90036]]\n",
      "1820 Cost: 6.1882625 \n",
      "Prediction:\n",
      " [[151.61006]\n",
      " [184.99051]\n",
      " [181.36253]\n",
      " [192.29085]\n",
      " [145.8955 ]]\n",
      "1830 Cost: 6.177871 \n",
      "Prediction:\n",
      " [[151.61441]\n",
      " [184.98743]\n",
      " [181.36374]\n",
      " [192.29272]\n",
      " [145.89061]]\n",
      "1840 Cost: 6.167553 \n",
      "Prediction:\n",
      " [[151.61873]\n",
      " [184.98433]\n",
      " [181.36494]\n",
      " [192.29457]\n",
      " [145.88573]]\n",
      "1850 Cost: 6.15722 \n",
      "Prediction:\n",
      " [[151.62305]\n",
      " [184.98132]\n",
      " [181.36612]\n",
      " [192.29646]\n",
      " [145.88087]]\n",
      "1860 Cost: 6.1469674 \n",
      "Prediction:\n",
      " [[151.62733]\n",
      " [184.97826]\n",
      " [181.36731]\n",
      " [192.29832]\n",
      " [145.87602]]\n",
      "1870 Cost: 6.136784 \n",
      "Prediction:\n",
      " [[151.63162]\n",
      " [184.97519]\n",
      " [181.3685 ]\n",
      " [192.30017]\n",
      " [145.87119]]\n",
      "1880 Cost: 6.1266146 \n",
      "Prediction:\n",
      " [[151.63588]\n",
      " [184.97221]\n",
      " [181.3697 ]\n",
      " [192.30206]\n",
      " [145.86638]]\n",
      "1890 Cost: 6.1164856 \n",
      "Prediction:\n",
      " [[151.64014]\n",
      " [184.96915]\n",
      " [181.37086]\n",
      " [192.3039 ]\n",
      " [145.86154]]\n",
      "1900 Cost: 6.106349 \n",
      "Prediction:\n",
      " [[151.6444 ]\n",
      " [184.96617]\n",
      " [181.37201]\n",
      " [192.30577]\n",
      " [145.85674]]\n",
      "1910 Cost: 6.096377 \n",
      "Prediction:\n",
      " [[151.64864]\n",
      " [184.96315]\n",
      " [181.3732 ]\n",
      " [192.3076 ]\n",
      " [145.85196]]\n",
      "1920 Cost: 6.086422 \n",
      "Prediction:\n",
      " [[151.65285]\n",
      " [184.96016]\n",
      " [181.37437]\n",
      " [192.30943]\n",
      " [145.84718]]\n",
      "1930 Cost: 6.076429 \n",
      "Prediction:\n",
      " [[151.65704]\n",
      " [184.95718]\n",
      " [181.37552]\n",
      " [192.3113 ]\n",
      " [145.8424 ]]\n",
      "1940 Cost: 6.0664945 \n",
      "Prediction:\n",
      " [[151.66127]\n",
      " [184.95422]\n",
      " [181.3767 ]\n",
      " [192.31317]\n",
      " [145.83766]]\n",
      "1950 Cost: 6.0566716 \n",
      "Prediction:\n",
      " [[151.6654 ]\n",
      " [184.95122]\n",
      " [181.3778 ]\n",
      " [192.31494]\n",
      " [145.83289]]\n",
      "1960 Cost: 6.046816 \n",
      "Prediction:\n",
      " [[151.66959]\n",
      " [184.94826]\n",
      " [181.37895]\n",
      " [192.31682]\n",
      " [145.82817]]\n",
      "1970 Cost: 6.0370646 \n",
      "Prediction:\n",
      " [[151.67377]\n",
      " [184.94534]\n",
      " [181.38013]\n",
      " [192.31865]\n",
      " [145.82346]]\n",
      "1980 Cost: 6.027308 \n",
      "Prediction:\n",
      " [[151.6779 ]\n",
      " [184.94235]\n",
      " [181.38124]\n",
      " [192.32047]\n",
      " [145.81873]]\n",
      "1990 Cost: 6.017637 \n",
      "Prediction:\n",
      " [[151.68202]\n",
      " [184.93942]\n",
      " [181.38239]\n",
      " [192.3223 ]\n",
      " [145.81404]]\n",
      "2000 Cost: 6.007992 \n",
      "Prediction:\n",
      " [[151.68614]\n",
      " [184.93648]\n",
      " [181.3835 ]\n",
      " [192.3241 ]\n",
      " [145.80934]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x_data = [[73.,80.,75.],[93.,88.,93.],\n",
    "         [89.,91.,90.],[96.,98.,100.],[73.,66.,70.]]\n",
    "y_data = [[152.],[185.],[180.],[196.],[142.]]\n",
    "# placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape = [None,3])\n",
    "Y = tf.placeholder(tf.float32, shape = [None,1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3,1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "# Hypothesis\n",
    "hypothesis = tf.matmul(X,W) + b\n",
    "# Simplified cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis-Y))\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(2001):\n",
    "        cost_val, hy_val, _ = sess.run(\n",
    "            [cost, hypothesis, train], feed_dict={X:x_data, Y:y_data})\n",
    "        if step % 10 == 0:\n",
    "            print(step, \"Cost:\", cost_val, \"\\nPrediction:\\n\",hy_val)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x가 3개로 늘어났으니까 W도 3개"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
